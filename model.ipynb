{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5a77d40e9246ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jotha\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jotha\\anaconda3\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jotha\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:48:23.809203800Z",
     "start_time": "2023-11-30T16:48:16.397051700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pokedex functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf4906357c6b3a3b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6862f4ff4dd821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:50:24.226618900Z",
     "start_time": "2023-11-30T16:50:24.213617500Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pokedex(path=\"pokedex/pokemon.csv\"):\n",
    "    pokedex = pd.read_csv(path)\n",
    "    return pokedex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2a70384c318d1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:50:24.504317Z",
     "start_time": "2023-11-30T16:50:24.490325500Z"
    }
   },
   "outputs": [],
   "source": [
    "# converts pokemon's name to corresponding pokemon's pokedex number\n",
    "def pokemon_name_to_number(name):\n",
    "    pokedex = make_pokedex()\n",
    "    return pokedex.index[pokedex['Name'] == name].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "168c69d70043bf20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:50:24.785085600Z",
     "start_time": "2023-11-30T16:50:24.743055100Z"
    }
   },
   "outputs": [],
   "source": [
    "# converts pokemon's pokedex number to corresponding pokemon's name\n",
    "def pokemon_number_to_name(number):\n",
    "    pokedex = make_pokedex()\n",
    "    return pokedex.iloc[number]['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Pokemon sprite data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2040123f69a4e1ee"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "467388624e0b4a91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T17:19:14.132671700Z",
     "start_time": "2023-11-30T17:19:06.087340900Z"
    }
   },
   "outputs": [],
   "source": [
    "sprites_number_name = []\n",
    "# iterate over pokemon in sample directory\n",
    "for i_pokemon, pokemon in enumerate(os.listdir('samples')):\n",
    "    # iterate over images in each pokemon's directory\n",
    "    for i_img, img in enumerate(os.listdir(os.path.join('samples', pokemon))):\n",
    "        fp = os.path.join('samples', pokemon, img)\n",
    "        # read in image\n",
    "        sprite_image = cv2.imread(fp)\n",
    "        # resize and convert image to np array\n",
    "        resized_sprite_image = np.array(cv2.resize(sprite_image, (50, 50)))\n",
    "        # convert to pokemon's pokedex number\n",
    "        pokemon_number = pokemon_name_to_number(pokemon)\n",
    "        # store image, number, name in cumulative list of other images\n",
    "        sprites_number_name.append([resized_sprite_image, pokemon_number, pokemon])\n",
    "\n",
    "# convert to pandas dataframe\n",
    "data = pd.DataFrame(sprites_number_name, columns = ['image', 'number', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c98c13a38ada8",
   "metadata": {},
   "source": [
    "## Check for duplicate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0ceb88c30eebacb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T17:19:17.892015100Z",
     "start_time": "2023-11-30T17:19:17.832517500Z"
    }
   },
   "outputs": [],
   "source": [
    "def hash_image(image):\n",
    "    # Convert the image array to bytes and then create an MD5 hash\n",
    "    return hashlib.md5(image.tobytes()).hexdigest()\n",
    "\n",
    "# Create a dictionary to store hashes and corresponding indices\n",
    "hash_dict = {}\n",
    "\n",
    "# Iterate through each image in the array\n",
    "for i, image in enumerate(data['image']):\n",
    "    # Get the hash of the current image\n",
    "    image_hash = hash_image(image)\n",
    "\n",
    "    # Check if the hash already exists in the dictionary\n",
    "    if image_hash in hash_dict:\n",
    "        hash_dict[image_hash].append(i)\n",
    "    else:\n",
    "        # If the hash is not in the dictionary, add it with the current index\n",
    "        hash_dict[image_hash] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d5f5501c569c125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T17:19:21.163521200Z",
     "start_time": "2023-11-30T17:19:21.154078800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Locate duplicate entries in the dataframe\n",
    "duplicate_loc = [hash_dict[hash][1] for hash in hash_dict if len(hash_dict[hash]) > 1]\n",
    "\n",
    "# Drop duplicate entries\n",
    "data.drop(duplicate_loc, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b18e89970469d3",
   "metadata": {},
   "source": [
    "## Test Displaying Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7ccd9ef97db9fd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T17:19:24.426199800Z",
     "start_time": "2023-11-30T17:19:24.176431200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 50, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load first image in dataframe\n",
    "img1 = data.iloc[0]['image']\n",
    "# print shape of image\n",
    "print(img1.shape)\n",
    "# plot image\n",
    "plt.imshow(img1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split sprite data and load into tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b600af89e7540b7"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eab32f0ebc997fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T17:19:27.518861900Z",
     "start_time": "2023-11-30T17:19:27.402680600Z"
    }
   },
   "outputs": [],
   "source": [
    "# load features\n",
    "X = data['image']\n",
    "# load labels\n",
    "y = data['number']\n",
    "# split data into test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# concat feature and labels together\n",
    "data_train = pd.concat([X_train, y_train], axis=1)\n",
    "data_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# convert training data to tensor\n",
    "tensor_X_train = torch.stack([torch.tensor(img, dtype=torch.float32) for img in data_train['image'].values])\n",
    "tensor_X_train = torch.transpose(tensor_X_train, 1, 2)\n",
    "tensor_X_train = torch.transpose(tensor_X_train, 1, 3)\n",
    "tensor_X_train = tensor_X_train.to(device)\n",
    "tensor_y_train = torch.tensor(data_train['number'].values)\n",
    "tensor_y_train = tensor_y_train.to(device)\n",
    "tensor_train = TensorDataset(tensor_X_train, tensor_y_train)\n",
    "\n",
    "# convert test data to tensor\n",
    "tensor_X_test = torch.stack([torch.tensor(img, dtype=torch.float32) for img in data_test['image'].values])\n",
    "tensor_X_test = torch.transpose(tensor_X_test, 1, 2)\n",
    "tensor_X_test = torch.transpose(tensor_X_test, 1, 3)\n",
    "tensor_X_test = tensor_X_test.to(device)\n",
    "tensor_y_test = torch.tensor(data_test['number'].values)\n",
    "tensor_y_test = tensor_y_test.to(device)\n",
    "tensor_test = TensorDataset(tensor_X_test, tensor_y_test)\n",
    "\n",
    "# put tensor data into DataLoader\n",
    "# train_loader = DataLoader(tensor_train, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(tensor_test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cabe721de9b6ff1"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "# cnn model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(64, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 50 * 50, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            # nn.Linear(512, 1024),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 256 * 50 * 50) \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# function to train model\n",
    "def train_model(model, train_loader, criterion, optimizer, epoch, print_loss=False):\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    total_samples = 0\n",
    "    correct_samples = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "    # for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(inputs)\n",
    "        loss = criterion(pred, labels)\n",
    "        running_loss.append(loss.item())\n",
    "        \n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        correct_samples += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if print_loss:\n",
    "        print(\"Epoch {} - loss: {:.4} - training accuracy: {:.2%}\".format(epoch + 1, np.mean(running_loss), correct_samples / total_samples))\n",
    "    return correct_samples / total_samples\n",
    "\n",
    "# function to evaluate the model\n",
    "def evaluate_model(model, test_loader, criterion, top_k=False, k=10):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    predictions, labels = [], []\n",
    "    eval_running_loss = []\n",
    "    with torch.no_grad():\n",
    "        for batch, label in test_loader:\n",
    "            pred = model(batch)\n",
    "            eval_loss = criterion(pred, label)\n",
    "            eval_running_loss.append(eval_loss.item())\n",
    "\n",
    "            if top_k:\n",
    "                topk_values, topk_indices = torch.topk(pred, k=k, dim=1)\n",
    "                for i, l in enumerate(label.tolist()):\n",
    "                    if l in topk_indices.tolist()[i]:\n",
    "                        correct += 1\n",
    "                        predictions.append(l)\n",
    "                        labels.append(l)\n",
    "                    else:\n",
    "                        predictions.append(topk_indices.tolist()[i][0])\n",
    "                        labels.append(l)\n",
    "                # print(label, topk_indices)\n",
    "            else:\n",
    "                correct += (torch.argmax(pred,dim=1)==label).sum().item()\n",
    "                predictions.extend(torch.argmax(pred, dim=1).tolist())\n",
    "                labels.extend(label.tolist())\n",
    "    acc = correct/len(test_loader.dataset)\n",
    "\n",
    "    # print(f\"Test Acccuracy: {acc}\")\n",
    "    return acc, predictions, labels\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:30:08.440871500Z",
     "start_time": "2023-12-01T20:30:08.384358100Z"
    }
   },
   "id": "3498cb9cb7d2ef26"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy, Precision, Recall, F1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71492fa08fe8b63a"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "def evaluate(predictions, labels):\n",
    "    accuracy = accuracy_score(labels, predictions, normalize=True)\n",
    "    precision = precision_score(labels, predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    print('Accuracy: ', accuracy)\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1 Score: ', f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T21:14:03.944283700Z",
     "start_time": "2023-12-01T21:14:03.928671700Z"
    }
   },
   "id": "15498434976e421"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function to train and test CNN model on sprite data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45fec0601432c29b"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def train_test_model(lr, batch_size, weight_decay, optimizer_name, epochs, print_loss=False):\n",
    "    cnn = CNN(num_classes=50)\n",
    "    cnn = cnn.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = optim.Adam(cnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = optim.SGD(cnn.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(cnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(tensor_train, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(tensor_test, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Training loop\n",
    "    # for epoch in tqdm(range(epochs)):  # Adjust the number of epochs as needed\n",
    "    for epoch in range(epochs):\n",
    "        training_accuracy = train_model(cnn, train_loader, criterion, optimizer, epoch, print_loss=print_loss)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    test_accuracy, predictions, labels = evaluate_model(cnn, test_loader, criterion)\n",
    "    \n",
    "    print(f\"LR: {lr}, Batch Size: {batch_size}, Weight Decay: {weight_decay}, Optimizer: {optimizer_name}, Training Accuracy: {round(training_accuracy, 5)}, Test Accuracy: {round(test_accuracy, 5)}\")\n",
    "    \n",
    "    evaluate(predictions, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T17:19:42.512416400Z",
     "start_time": "2023-11-30T17:19:42.501408900Z"
    }
   },
   "id": "d648d0c697d2aaf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and test model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b75cffbb2226d1a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [04:04<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 2.877 - training accuracy: 25.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [04:03<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - loss: 1.133 - training accuracy: 66.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [03:56<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - loss: 0.6308 - training accuracy: 80.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [03:57<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - loss: 0.3824 - training accuracy: 88.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [04:07<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - loss: 0.2455 - training accuracy: 92.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [04:02<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - loss: 0.1496 - training accuracy: 95.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [04:32<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - loss: 0.1065 - training accuracy: 97.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [04:11<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - loss: 0.07196 - training accuracy: 98.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [03:52<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - loss: 0.06283 - training accuracy: 98.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [03:51<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - loss: 0.04589 - training accuracy: 99.17%\n",
      "LR: 0.0004, Batch Size: 16, Weight Decay: 0.0001, Optimizer: sgd, Training Accuracy: 0.99169, Test Accuracy: 0.80409\n"
     ]
    }
   ],
   "source": [
    "train_test_model(lr=4e-4, batch_size=16, weight_decay=1e-4, optimizer_name='sgd', epochs=10, print_loss=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T17:50:16.051827400Z",
     "start_time": "2023-11-29T17:09:25.918746500Z"
    }
   },
   "id": "3357309475f3ca15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load trained model and test on sprite data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26f38c39bb5706e9"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8180839612486545\n",
      "Accuracy:  0.8180839612486545\n",
      "Precision:  0.8294961116995407\n",
      "Recall:  0.8180839612486545\n",
      "F1 Score:  0.8143982878538758\n"
     ]
    }
   ],
   "source": [
    "# load state dict of trained model\n",
    "loaded_state_dict = torch.load('cnn_state_dict.pth', map_location=torch.device('cpu'))\n",
    "cnn_load = CNN(num_classes=50)\n",
    "cnn_load.load_state_dict(loaded_state_dict)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 16\n",
    "\n",
    "test_loader = DataLoader(tensor_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test model on sprite test data\n",
    "test_accuracy, predictions, labels = evaluate_model(cnn_load, test_loader, criterion)\n",
    "print(test_accuracy)\n",
    "evaluate(predictions, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T17:54:43.480217Z",
     "start_time": "2023-12-01T17:54:30.614204500Z"
    }
   },
   "id": "91050a6ac15c4ce4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Pokemon battle image data and convert to tensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40f7bc0d66d8fddb"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "battle_number_name = []\n",
    "# iterate over pokemon in sample directory\n",
    "for i_pokemon, pokemon_file in enumerate(os.listdir('find_pkm_in_battle/ScreenShoots/output')):\n",
    "    # find start of pokemon name\n",
    "    start = 0\n",
    "    while not ('a' <= pokemon_file[start] <= 'z'):\n",
    "        start += 1\n",
    "    # find end of pokemon name\n",
    "    end = start\n",
    "    while 'a' <= pokemon_file[end] <= 'z':\n",
    "        end += 1\n",
    "    # pokemon name\n",
    "    pokemon = pokemon_file[start:end]\n",
    "    # check if pokemon was trained by the model\n",
    "    if pokemon_name_to_number(pokemon) <= 50:\n",
    "        fp = os.path.join('find_pkm_in_battle/ScreenShoots/output',pokemon_file)\n",
    "        # read in image\n",
    "        sprite_image = cv2.imread(fp)\n",
    "        # resize and convert image to np array\n",
    "        resized_sprite_image = np.array(cv2.resize(sprite_image, (50, 50)))\n",
    "        # convert to pokemon's pokedex number\n",
    "        pokemon_number = pokemon_name_to_number(pokemon)\n",
    "        # store image, number, name in cumulative list of other images\n",
    "        battle_number_name.append([resized_sprite_image, pokemon_number, pokemon])\n",
    "\n",
    "# convert to pandas dataframe\n",
    "data_battle = pd.DataFrame(battle_number_name, columns = ['image', 'number', 'name'])\n",
    "\n",
    "# load features\n",
    "X_battle = data_battle['image']\n",
    "# load labels\n",
    "y_battle = data_battle['number']\n",
    "\n",
    "# concat feature and labels together\n",
    "data_battle_test = pd.concat([X_battle, y_battle], axis=1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# convert battle data to tensor\n",
    "tensor_X_battle = torch.stack([torch.tensor(img, dtype=torch.float32) for img in data_battle_test['image'].values])\n",
    "tensor_X_battle = torch.transpose(tensor_X_battle, 1, 2)\n",
    "tensor_X_battle = torch.transpose(tensor_X_battle, 1, 3)\n",
    "tensor_X_battle = tensor_X_battle.to(device)\n",
    "tensor_y_battle = torch.tensor(data_battle_test['number'].values)\n",
    "tensor_y_battle = tensor_y_battle.to(device)\n",
    "tensor_battle = TensorDataset(tensor_X_battle, tensor_y_battle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:48:48.153830100Z",
     "start_time": "2023-12-01T20:48:47.147342900Z"
    }
   },
   "id": "2ee10012e7866e70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load trained model and test on battle data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8ca0f6f6590cdf8"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.14666666666666667\n",
      "Precision:  0.1961056487372277\n",
      "Recall:  0.14666666666666667\n",
      "F1 Score:  0.13594465962887017\n"
     ]
    }
   ],
   "source": [
    "# load state dict of trained model\n",
    "loaded_state_dict = torch.load('cnn_state_dict.pth', map_location=torch.device('cpu'))\n",
    "cnn_load = CNN(num_classes=50)\n",
    "cnn_load.load_state_dict(loaded_state_dict)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 16\n",
    "\n",
    "# put battle tensor into DataLoader\n",
    "battle_loader = DataLoader(tensor_battle, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test model on battle data\n",
    "test_accuracy, predictions, labels = evaluate_model(cnn_load, battle_loader, criterion, top_k=True, k=5)\n",
    "evaluate(predictions, labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T21:14:25.157117800Z",
     "start_time": "2023-12-01T21:14:18.576366Z"
    }
   },
   "id": "d99a42c3e1923f68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6c1c4931a51efe6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
